{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74598a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f58e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_flag = '[PAD]'\n",
    "unk_flag = '[UNK]'\n",
    "begin_flag = '[GO]'\n",
    "end_flag = '[EOS]'\n",
    "\n",
    "\n",
    "def read_json_file(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, 'r', encoding='utf8') as fp:\n",
    "        json_data = json.load(fp) \n",
    "    return json_data\n",
    "\n",
    "def read_text_file(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, 'r', encoding='utf8') as fp:\n",
    "        txt = fp.read() \n",
    "    return txt\n",
    "    \n",
    "def save_text(path, text):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text) \n",
    "    \n",
    "def get_q_a_from_dict(qa_dict, q_key='Question', a_key='Answer'):\n",
    "    q = qa_dict.get(q_key, '')\n",
    "    a = qa_dict.get(a_key, '')\n",
    "    return q, a\n",
    "    \n",
    "def creat_vocab(path):\n",
    "    json_data = read_json_file(path)\n",
    "    char_dict = {}\n",
    "    # trian\n",
    "    for qa in json_data['train']:\n",
    "        q, a = get_q_a_from_dict(qa) \n",
    "        for c in str(a) + str(q):\n",
    "            char_dict[c] = char_dict.get(c, 0) + 1\n",
    "\n",
    "    for qa in json_data['val']:\n",
    "        q, a = get_q_a_from_dict(qa) \n",
    "        for c in str(a) + str(q):\n",
    "            char_dict[c] = char_dict.get(c, 0) + 1\n",
    "    \n",
    "    flags = [pad_flag, unk_flag, begin_flag, end_flag]\n",
    "    char_items = sorted(char_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "    chars = [item[0] for item in char_items]\n",
    "    vocab = flags + chars\n",
    "    vocab = [c.strip() for c in vocab if len(c.strip()) > 0]\n",
    "    return vocab\n",
    "\n",
    "def read_vocab(qa_path, vocab_path, ignore_exist=False):\n",
    "    if not ignore_exist and  os.path.exists(vocab_path):\n",
    "        vocab_txt = read_text_file(vocab_path)\n",
    "        vocab = vocab_txt.split(\"\\n\")\n",
    "        return vocab\n",
    "    else:\n",
    "        vocab = creat_vocab(qa_path)\n",
    "        save_text(vocab_path, \"\\n\".join(vocab))\n",
    "        return vocab\n",
    "    \n",
    "vocab = read_vocab(qa_path=utils.path.fm_qa_json_path, \n",
    "                   vocab_path=utils.path.fm_qa_vocab_path, \n",
    "                   ignore_exist=False)\n",
    "i2c = {i:c for i, c in enumerate(vocab)}\n",
    "c2i = {c:i for i, c in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "pad_id = c2i.get(pad_flag, 0)\n",
    "unk_id = c2i.get(unk_flag, 1)\n",
    "begin_id = c2i.get(begin_flag, 2)\n",
    "end_id = c2i.get(end_flag, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f878d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先快速处理吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fa644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_q_a_text(qa_path, model='train'):\n",
    "    json_data = read_json_file(qa_path)\n",
    "    key = model\n",
    "    q_list, a_list = [], []\n",
    "    for qa in json_data[model]:\n",
    "        q, a = get_q_a_from_dict(qa) \n",
    "        q_list.append(q)\n",
    "        a_list.append(a)\n",
    "    return q_list, a_list\n",
    "\n",
    "\n",
    "def text_to_ids(texts, max_len=32, add_begin=True, add_end=True):\n",
    "    ids = []\n",
    "    for line in texts:\n",
    "        line = line[:max_len-2]\n",
    "        id_line = [c2i.get(c, unk_id) for c in line]\n",
    "        if add_begin:\n",
    "            id_line = [begin_id] + id_line\n",
    "        if add_end:\n",
    "            id_line = id_line + [end_id]\n",
    "        id_line = id_line + [pad_id] * (max_len - len(id_line))\n",
    "        ids.append(id_line)\n",
    "    return ids\n",
    "\n",
    "\n",
    "max_len = 32\n",
    "q_train, a_train = read_q_a_text(utils.path.fm_qa_json_path, model='train')\n",
    "      \n",
    "q_train_ids = text_to_ids(texts=q_train, max_len=32, add_begin=True, add_end=True)\n",
    "a_train_input_ids = text_to_ids(texts=a_train, max_len=32, add_begin=True, add_end=False)\n",
    "a_train_label_ids = text_to_ids(texts=a_train, max_len=32, add_begin=False, add_end=True)\n",
    "\n",
    "\n",
    "q_val, a_val = read_q_a_text(utils.path.fm_qa_json_path, model='val')\n",
    "      \n",
    "q_val_ids = text_to_ids(texts=q_val, max_len=32, add_begin=True, add_end=True)\n",
    "a_val_input_ids = text_to_ids(texts=a_val, max_len=32, add_begin=True, add_end=False)\n",
    "a_val_label_ids = text_to_ids(texts=a_val, max_len=32, add_begin=False, add_end=True)\n",
    "\n",
    "\n",
    "save_pickle(q_train_ids, utils.path.fm_qa_train_src_path)\n",
    "save_pickle(a_train_input_ids, utils.path.fm_qa_train_trg_input_path)\n",
    "save_pickle(a_train_label_ids, utils.path.fm_qa_train_trg_label_path)\n",
    "\n",
    "save_pickle(q_val_ids, utils.path.fm_qa_val_src_path)\n",
    "save_pickle(a_val_input_ids, utils.path.fm_qa_val_trg_input_path)\n",
    "save_pickle(a_val_label_ids, utils.path.fm_qa_val_trg_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f5ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "import pickle\n",
    "\n",
    "def save_pickle(data, file_name):\n",
    "    f = open(file_name, \"wb\")\n",
    "    pickle.dump(data, f)\n",
    "    f.close()\n",
    "def load_pickle(file_name):\n",
    "    f = open(file_name, \"rb+\")\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d063db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906349a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff7eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e88df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2303d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204a11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict = {}\n",
    "# trian\n",
    "for qa in json_data['train']:a\n",
    "    q = qa.get('Question', \"\")\n",
    "    a = qa.get('Answer', \"\")\n",
    "    for c in str(a) + str(q):\n",
    "        char_dict[c] = char_dict.get(c, 0) + 1\n",
    "    \n",
    "for qa in json_data['val']:\n",
    "    q = qa.get('Question', \"\")\n",
    "    a = qa.get('Answer', \"\")\n",
    "    for c in str(a) + str(q):\n",
    "        char_dict[c] = char_dict.get(c, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044dc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = ['[PAD]', '[UNK]', '[GO]', '[ESO]']\n",
    "\n",
    "char_items = sorted(char_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "chars = [item[0] for item in char_items]\n",
    "vocab = flags + chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd0020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.fm_qa_vocab_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(vocab)) \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f9a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061013f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf715b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb16d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a9d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e1ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799fbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54c439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f494dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
